/*
"Copyright 2019 Intel Corporation.

The source code, information and material ("Material") contained herein is owned by Intel Corporation or its
suppliers or licensors, and title to such Material remains with Intel Corporation or its suppliers or licensors.
The Material contains proprietary information of Intel or its suppliers and licensors. The Material is
protected by worldwide copyright laws and treaty provisions. No part of the Material may be used, copied,
reproduced, modified, published, uploaded, posted, transmitted, distributed or disclosed in any way without Intel's
prior express written permission. No license under any patent, copyright or other intellectual property rights in
the Material is granted to or conferred upon you, either expressly, by implication, inducement, estoppel or otherwise.
Any license under such intellectual property rights must be express and approved by Intel in writing.


Include supplier trademarks or logos as supplier requires Intel to use, preceded by an asterisk. An asterisked footnote
can be added as follows: *Third Party trademarks are the property of their respective owners.

Unless otherwise agreed by Intel in writing, you may not remove or alter this notice or any other notice
embedded in Materials by Intel or Intel's suppliers or licensors in any way."
*/



// OpenVinoTestDll.cpp : Defines the entry point for the application.
//

#include "OpenVinoData.h"

#include <iomanip>
#include <fstream>
#include <vector>
#include <memory>
#include <cstdlib>
#include <string>
#include <limits>
#include <d3d11.h>

#include <opencv2/opencv.hpp>
#include <ie/inference_engine.hpp>
#include "openvino/openvino.hpp"
#include "openvino/runtime/intel_gpu/properties.hpp"
#include "openvino/runtime/intel_gpu/ocl/ocl.hpp"

#include "OpenCLUtil.h"

using namespace std;
using namespace InferenceEngine;

/*
 * @brief Initialize OpenVino with passed model files
 * @param modelXmlFilePath
 * @param modelBinFilePath
 * @param modelLabelFilePath
 */
void 
OpenVinoData::Initialize(
	string modelXmlFilePath,
	string modelBinFilePath,
	int inferWidth,
	int inferHeight)
{

	// --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
	clog << "2. Read IR..." << endl;
	Core core;
	/** Set batch size to 1 **/
	CNNNetwork network = core.ReadNetwork(modelXmlFilePath);
	auto shapes = network.getInputShapes();
	for (auto& shape : shapes)
		shape.second[0] = 1;
	network.reshape(shapes);


	// --------------------------- 2. Configure input & output ---------------------------------------------
	clog << "3. Configure input/output..." << endl;
	input_info = network.getInputsInfo().begin()->second;
	input_name = network.getInputsInfo().begin()->first;


	cv::Size& new_input_resolution = cv::Size(inferWidth, inferHeight);
	SizeVector input_dims = input_info->getTensorDesc().getDims();
	input_dims[0] = 1;
	if (new_input_resolution != cv::Size()) {
		input_dims[2] = static_cast<size_t>(new_input_resolution.height);
		input_dims[3] = static_cast<size_t>(new_input_resolution.width);
	}

	std::map<std::string, SizeVector> input_shapes;
	input_shapes[network.getInputsInfo().begin()->first] = input_dims;
	network.reshape(input_shapes);

	input_info->setLayout(Layout::NCHW);
	input_info->setPrecision(Precision::FP32);

	DataPtr output_info = network.getOutputsInfo().begin()->second;
	output_name = network.getOutputsInfo().begin()->first;

	output_info->setPrecision(Precision::FP32);

	// --------------------------- 3. Loading model to the plugin ------------------------------------------
	clog << "4. Loading model..." << endl;
	executable_network = core.LoadNetwork(network, "CPU");//, cnnConfig.execNetworkConfig);

	clog << "Intialized." << endl;
}

/*
 * @brief Call infer using loaded model files
 * @param filePath
 * @param modelBinFilePath
 * @param modelLabelFilePath
 */
bool
OpenVinoData::Infer( 
	std::string filePath, int* w, int* h, float* out)
{
	// --------------------------- 5. Create infer request -------------------------------------------------
	clog << "5. Creating request..." << endl;
	InferRequest infer_request = executable_network.CreateInferRequest();

	// return image_file_name;

	// --------------------------- 6. Prepare input --------------------------------------------------------
	cout << "6. Prepare input..." << endl;
	int height = 1080;
	int width = 1920;
	//cv::Mat image(height, width, CV_8UC4, texture);
	cv::Mat image = cv::imread(filePath);
	cv::Mat outputImage;
	cv::cvtColor(image, image, cv::COLOR_BGRA2RGB);
	image.convertTo(image, CV_32F, 1.0 / 255, 0);
	/* Resize manually and copy data from the image to the input blob */
	Blob::Ptr input = infer_request.GetBlob(input_name);
	auto input_data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();

	auto size = cv::Size(input_info->getTensorDesc().getDims()[3], input_info->getTensorDesc().getDims()[2]);
	cv::resize(image, image, size);

	size_t channels_number = input->getTensorDesc().getDims()[1];
	size_t image_size = input->getTensorDesc().getDims()[3] * input->getTensorDesc().getDims()[2];

	for (size_t pid = 0; pid < image_size; ++pid) {
		for (size_t ch = 0; ch < channels_number; ++ch) {
			//input of new model is in range -1,1 with float precision
			input_data[ch * image_size + pid] = image.at<cv::Vec3f>(pid)[ch]*2-1;
		}
	}
	// -----------------------------------------------------------------------------------------------------

	// --------------------------- 7. Do inference --------------------------------------------------------
	clog << "7. Do inference..." << endl;
	/* Running the request synchronously */
	infer_request.Infer();
	// -----------------------------------------------------------------------------------------------------

	// --------------------------- 8. Process output ------------------------------------------------------
	clog << "8. Process output..." << endl;
	Blob::Ptr output = infer_request.GetBlob(output_name);
	auto output_shape = output->getTensorDesc().getDims();
	int length = output_shape[0] * output_shape[1] * output_shape[2] * output_shape[3];
	LockedMemory<const void> blobMapped = as<MemoryBlob>(output)->rmap();
	float* output_data_pointer = blobMapped.as<float*>();
	std::vector<float> output_data(output_data_pointer, output_data_pointer + length);

	//output of new model is in range (0,255)
	std::vector<uint8_t> convert_output_data;
	convert_output_data.reserve(output_data.size());
	for (const auto& f : output_data) {
		convert_output_data.push_back(uint8_t(f));
	}

	//align result dimension
	//output_data  = transpose4d(output_data, ieSizeToVector(output_shape), { 0, 3, 1, 2 });
	int rows = output_shape[2];
	int cols = output_shape[3];
	if (convert_output_data.size() == rows * cols * 3) // check that the rows and cols match the size of your vector
	{
		//copy vector to mat
		cv::Mat channelR(rows, cols, CV_32FC1, convert_output_data.data());
		cv::Mat channelG(rows, cols, CV_32FC1, convert_output_data.data() + cols * rows);
		cv::Mat channelB(rows, cols, CV_32FC1, convert_output_data.data() + 2 * cols * rows);
		// RGB2BGR
		std::vector<cv::Mat> channels{ channelB, channelG, channelR };

		// Create the output matrix
		merge(channels, outputImage);
	}
	
	int arraysize = outputImage.rows * outputImage.cols * outputImage.channels();
	memcpy(out, outputImage.data, arraysize * sizeof(float));
	*w = outputImage.size().width;
	*h = outputImage.size().height;

	//cv::imwrite("test1.png", outputImage);
	return true;
}

/*
 * @brief Call infer using loaded model files
 * @param filePath
 * @param modelBinFilePath
 * @param modelLabelFilePath
 */
bool
OpenVinoData::Infer(
	unsigned char* inferdata, int inwidth, int inheight, unsigned char* out, bool debug_flag)
{
	// --------------------------- 5. Create infer request -------------------------------------------------
	clog << "5. Creating request..." << endl;
	InferRequest infer_request = executable_network.CreateInferRequest();

	// return image_file_name;

	// --------------------------- 6. Prepare input --------------------------------------------------------
	cout << "6. Prepare input..." << endl;

	cv::Mat outputImage;
	cv::Mat image(inheight, inwidth, CV_8UC3, inferdata);
	image.convertTo(image, CV_32F, 1.0 / 255, 0);
	if (debug_flag)
	{
		cv::imwrite("input.png", image);
	}
	/*
	cv::Mat image = cv::imread(filePath);
	cv::cvtColor(image, image, cv::COLOR_BGRA2RGB);*/
	
	/* Resize manually and copy data from the image to the input blob */
	Blob::Ptr input = infer_request.GetBlob(input_name);
	auto input_data = input->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();

	
	auto size = cv::Size(input_info->getTensorDesc().getDims()[3], input_info->getTensorDesc().getDims()[2]);
	cv::resize(image, image, size);

	size_t channels_number = input->getTensorDesc().getDims()[1];
	size_t image_size = input->getTensorDesc().getDims()[3] * input->getTensorDesc().getDims()[2];

	for (size_t pid = 0; pid < image_size; ++pid) {
		for (size_t ch = 0; ch < channels_number; ++ch) {
			//input of new model is in range -1,1 with float precision
			input_data[ch * image_size + pid] = image.at<cv::Vec3f>(pid)[ch]*2-1;
		}
	}
	// -----------------------------------------------------------------------------------------------------

	// --------------------------- 7. Do inference --------------------------------------------------------
	clog << "7. Do inference..." << endl;
	/* Running the request synchronously */
	infer_request.Infer();
	// -----------------------------------------------------------------------------------------------------

	// --------------------------- 8. Process output ------------------------------------------------------
	clog << "8. Process output..." << endl;
	Blob::Ptr output = infer_request.GetBlob(output_name);
	auto output_shape = output->getTensorDesc().getDims();
	int length = output_shape[0] * output_shape[1] * output_shape[2] * output_shape[3];
	LockedMemory<const void> blobMapped = as<MemoryBlob>(output)->rmap();
	float* output_data_pointer = blobMapped.as<float*>();
	std::vector<float> output_data(output_data_pointer, output_data_pointer + length);

	//output of new model is in range (0,255)
	std::vector<uint8_t> convert_output_data;
	convert_output_data.reserve(output_data.size());
	for (const auto& f : output_data) {
		convert_output_data.push_back(uint8_t(f));
	}

	//align result dimension
	//output_data  = transpose4d(output_data, ieSizeToVector(output_shape), { 0, 3, 1, 2 });
	int rows = output_shape[2];
	int cols = output_shape[3];
	if (convert_output_data.size() == rows * cols * 3) // check that the rows and cols match the size of your vector
	{
		//copy vector to mat
		cv::Mat channelR(rows, cols, CV_8UC1, convert_output_data.data());
		cv::Mat channelG(rows, cols, CV_8UC1, convert_output_data.data() + cols * rows);
		cv::Mat channelB(rows, cols, CV_8UC1, convert_output_data.data() + 2 * cols * rows);
		// RGB2BGR
		std::vector<cv::Mat> channels{ channelB, channelG, channelR };

		// Create the output matrix
		merge(channels, outputImage);
	}

	if(debug_flag)
	{
		cv::imwrite("output.png", outputImage);
	}
	
	int arraysize = outputImage.rows * outputImage.cols * outputImage.channels();
	memcpy(out, outputImage.data, arraysize * sizeof(unsigned char));

	//cv::imwrite("test1.png", outputImage);
	return true;
}

bool OpenVinoData::Create_OCLCtx(ID3D11Device* d3dDevice)
{
	m_pD3D11Dev = d3dDevice;	
	m_pD3D11Dev->GetImmediateContext(&m_pD3D11Cxt);

	if (!ocl.Init()) {
		return -1;
	}
	oclEnv = ocl.GetEnv(d3dDevice).get();
	if (!oclEnv) {
		std::cerr << "Failed to get OCL environment for the session" << std::endl;
		return -1;
	}

	oclStore = CreateFilterStore(oclEnv, "reorder_data_test.cl");
	srcConversionKernel = dynamic_cast<SourceConversion*>(oclStore->CreateKernel("srcConversion"));
	return 1;
}

/**
	 * @brief Initialize OpenVino with passed model files and opencl context
	 * @param modelXmlFilePath
	 * @param ctx
	 * @param inferWidth
	 * @param inferHeight
	 */
void OpenVinoData::Initialize_BaseOCL(
	std::string modelXmlFilePath,
	int inferWidth,
	int inferHeight)
{
	D3D11_TEXTURE2D_DESC desc_ovrgba_copy;

	desc_ovrgba_copy.Width = inferWidth;
	desc_ovrgba_copy.Height = inferHeight;
	desc_ovrgba_copy.MipLevels = 1;
	desc_ovrgba_copy.ArraySize = 1;
	desc_ovrgba_copy.Format = DXGI_FORMAT_R8G8B8A8_UNORM;
	desc_ovrgba_copy.SampleDesc.Count = 1;
	desc_ovrgba_copy.SampleDesc.Quality = 0;
	desc_ovrgba_copy.BindFlags = 0;
	desc_ovrgba_copy.Usage = D3D11_USAGE_STAGING;
	desc_ovrgba_copy.CPUAccessFlags = D3D11_CPU_ACCESS_READ;
	desc_ovrgba_copy.MiscFlags = 0;
	HRESULT  r = m_pD3D11Dev->CreateTexture2D(&desc_ovrgba_copy, 0, &m_ovSurfaceRGBA_cpu_copy);
	if (FAILED(r))
	{
		throw std::runtime_error("Can't create DX texture");
	}

	//1) Reading network 
	ov::Core core;
	core.set_property(ov::cache_dir("cache"));
	auto model = core.read_model(modelXmlFilePath);

	ov::preprocess::PrePostProcessor ppp(model);
	// 2)Setting input info
	ppp.input().tensor().
		set_layout("NCHW").
		set_element_type(ov::element::u8).
		set_color_format(ov::preprocess::ColorFormat::RGB).
		//set_shape({ 1,3,480,640}).
		set_memory_type(ov::intel_gpu::memory_type::buffer);

	// 3)Adding explicit preprocessing steps:
	ppp.input().preprocess()
		//.convert_color(ov::preprocess::ColorFormat::RGB)
		//.convert_layout("NCHW")
		//.resize(ov::preprocess::ResizeAlgorithm::RESIZE_LINEAR)
		.convert_element_type(ov::element::f32)
		.mean(127.5)
		.scale(127.5);

	ppp.input().model().set_layout("NCHW");

	// 4)Setting output info
	ppp.output().tensor()
		.set_element_type(ov::element::u8);

	model = ppp.build();

	// 5) reshape mode input
	input_shape = { 1,3,static_cast<size_t>(inferHeight), static_cast<size_t>(inferWidth) };
	model->reshape(input_shape);

	// 6)Loading model to the device -------------------------------------------
	auto remote_context = ov::intel_gpu::ocl::ClContext(core, oclEnv->GetContext());
	_oclCtx = oclEnv->GetContext();
	compiled_model = core.compile_model(model, remote_context); 
	//ov::serialize(compiled_model.get_runtime_model(), "test_graph.xml");
	// 7)Creating infer request ------------------------------------------------
	infer_request = compiled_model.create_infer_request();

	// 8)Create input and output GPU Blobs
	_inputBuffer = cl::Buffer(_oclCtx, CL_MEM_READ_WRITE, input_shape[1] * input_shape[2] * input_shape[3] * sizeof(uint8_t), NULL, NULL);
	_outputBuffer = cl::Buffer(_oclCtx, CL_MEM_READ_WRITE, input_shape[1] * input_shape[2] * input_shape[3] * sizeof(uint8_t), NULL, NULL);
	auto shared_in_blob = remote_context.create_tensor(ov::element::u8, input_shape, _inputBuffer);
	auto shared_output_blob = remote_context.create_tensor(ov::element::u8, input_shape, _outputBuffer);  //style transfer output has the same shape with input
	infer_request.set_input_tensor(shared_in_blob);
	infer_request.set_output_tensor(shared_output_blob);
}


/**
 * @brief Call infer using DirectX Texture2D RGBA
 * @param input_surface, input Texture2D RGBA data
 * @param output_surface, output Texture2D RGBA data
 * @param surfaceWidth, width of Texture2D
 * @param surfaceHeight, height of Texture2D
 * @param debug_flag, debug mode
 */

bool OpenVinoData::Infer(
	ID3D11Texture2D* input_surface, 
	ID3D11Texture2D* output_surface, 
	int surfaceWidth,
	int surfaceHeight,
	bool debug_flag)
{
	if (input_shape[2] != surfaceHeight ||
		input_shape[3] != surfaceWidth)
	{
		clog << "The surface size is not consistent with model input size" << endl;
	}

	srcConversionKernel->debug_flag = debug_flag;
	if (!srcConversionKernel->SetArgumentsRGBtoRGBbuffer(input_surface, _inputBuffer.get(), surfaceWidth, surfaceHeight)) {
		return false;
	}
	if (!srcConversionKernel->Run()) {
		return false;
	}

	infer_request.infer();

	if (!srcConversionKernel->SetArgumentsRGBbuffertoRGBA(_outputBuffer.get(), output_surface, surfaceWidth, surfaceHeight)) {
		return false;
	}
	if (!srcConversionKernel->Run()) {
		return false;
	}


	if (debug_flag)
	{
		m_pD3D11Cxt->CopyResource(m_ovSurfaceRGBA_cpu_copy, output_surface);
		UINT subResource = ::D3D11CalcSubresource(0, 0, 1);
		D3D11_MAPPED_SUBRESOURCE mappedTex;
		HRESULT r = m_pD3D11Cxt->Map(m_ovSurfaceRGBA_cpu_copy, subResource, D3D11_MAP_READ, 0, &mappedTex);
		if (FAILED(r))
		{
			throw std::runtime_error("surface mapping failed!");
		}
		cv::Mat m(surfaceHeight, surfaceWidth, CV_8UC4, mappedTex.pData, mappedTex.RowPitch);
		cv::cvtColor(m, m, cv::COLOR_RGBA2BGR);
		cv::imwrite("output_texture.png", m);

	}
	

	//debug
	// for (auto&& output : compiled_model.outputs()) {
	//const std::string name = output.get_names().empty() ? "NONE" : output.get_any_name();
	//if (name == "NONE")
	//{
	//	continue;
	//}

	//const ov::Tensor& output_tensor = infer_request.get_tensor(name);

	//auto data_size = output_tensor.get_size();
	//auto data = output_tensor.data<uint8_t>();
	//int rows = surfaceHeight;
	//int cols = surfaceWidth;
	////copy vector to mat
	//cv::Mat channelR(input_shape[2], input_shape[3], CV_8UC1, data);
	//cv::Mat channelG(input_shape[2], input_shape[3], CV_8UC1, data + input_shape[1] * input_shape[2]);
	//cv::Mat channelB(input_shape[2], input_shape[3], CV_8UC1, data + 2 * input_shape[1] * input_shape[2]);
	//// RGB2BGR
	//std::vector<cv::Mat> channels{ channelB, channelG, channelR };
	//// Create the output matrix
	//cv::Mat outputImage;
	//merge(channels, outputImage);
	////cv::Mat outputImage(cv::Size(cols, rows), CV_8UC3, data);
	//cv::imwrite("styled.png", outputImage);
    //}
}
